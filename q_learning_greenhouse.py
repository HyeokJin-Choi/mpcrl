# nohup python -u q_learning_greenhouse.py > run.log 2>&1 & 
# disown
# ìœ„ ë‘ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰ì‹œí‚¬ ê²ƒ.

# ps -ef | grep q_learning_greenhouse.py í”„ë¡œì„¸ìŠ¤ í™•ì¸
# tail -f run.log ë¡œê·¸ íŒŒì¼ ëª¨ë‹ˆí„°ë§
# top -p 13719 CPU/RAM ì‚¬ìš© í™•ì¸, ìˆ«ìëŠ” ë°°ì •ëœ PID ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•  ê²ƒ.

# grep "\[CKPT\] Saved at episode" -n run.log | tail ì§€ê¸ˆ ëª‡ ì—í”¼ì†Œë“œê¹Œì§€ ëë‚¬ëŠ”ì§€ í™•ì¸

# nohup python -u q_learning_greenhouse.py > run.log 2>&1 & 
# disown
# ìœ„ ë‘ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰ì‹œí‚¬ ê²ƒ.

import os, time, signal
import importlib
import logging
import pickle
import sys
from typing import Literal

import casadi as cs
import numpy as np
from gymnasium.wrappers import NormalizeReward, TimeLimit

from mpcrl import LearnableParameter, LearnableParametersDict
from mpcrl.wrappers.agents import Evaluate, Log, RecordUpdates
from mpcrl.wrappers.envs import MonitorEpisodes

from agents.greenhouse_agent import GreenhouseLearningAgent
from greenhouse.env import LettuceGreenHouse
from greenhouse.model import Model
from mpcs.learning import LearningMpc
from utils.plot import plot_greenhouse


# --------------------------------------------------------
# ---------- Utils: safe array shaping & extraction ----------
import numpy as np

def squeeze_last_if_one(a):
    """
    ë§ˆì§€ë§‰ ì¶•ì˜ í¬ê¸°ê°€ 1ì´ë©´ squeeze. ì—í”¼ì†Œë“œë³„ ê¸¸ì´ê°€ ë‹¤ë¥¸ ragged ë¦¬ìŠ¤íŠ¸/ë°°ì—´(object dtype)ë„ ì•ˆì „ ì²˜ë¦¬.
    """
    a = np.asarray(a, dtype=object)
    if a.dtype == object:  # ì—í”¼ì†Œë“œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        out = []
        for ep in a:
            ep_arr = np.asarray(ep)
            if ep_arr.ndim >= 1 and ep_arr.shape[-1] == 1:
                ep_arr = np.squeeze(ep_arr, axis=-1)
            out.append(ep_arr)
        return np.array(out, dtype=object)
    # ì¼ë°˜ ndarray
    if a.ndim >= 1 and a.shape[-1] == 1:
        return np.squeeze(a, axis=-1)
    return a


def stack_disturbances(env):
    """
    MonitorEpisodes ë˜í¼ì— ì €ì¥ëœ ì „ì²´ ì—í”¼ì†Œë“œì˜ ì™¸ë€ í”„ë¡œíŒŒì¼ì„ object ë°°ì—´ë¡œ ë°˜í™˜.
    ì—†ìœ¼ë©´ ë¹ˆ object ë°°ì—´.
    """
    try:
        d = env.get_wrapper_attr('disturbance_profiles_all_episodes')
    except Exception:
        d = None
    if d is None:
        return np.array([], dtype=object)
    return np.asarray(d, dtype=object)


def build_TD_matrix(td_errors, R_tr, num_episodes):
    """
    TD ì—ëŸ¬ë¥¼ ì—í”¼ì†Œë“œ ê²½ê³„ì— ë§ì¶° 2D(object->ragged safe)ë¡œ ì¬ë°°ì—´.
    R_trì˜ ì—í”¼ì†Œë“œ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ë‚¸ë‹¤.
    """
    ep_lens = [len(r) for r in R_tr]
    flat = np.asarray(td_errors, dtype=float).ravel()
    total = sum(ep_lens)
    flat = flat[:total] if total > 0 else flat[:0]
    if len(ep_lens) > 1 and total > 0:
        splits = np.cumsum(ep_lens[:-1])
        per_ep = np.split(flat, splits)
    elif total > 0:
        per_ep = [flat]
    else:
        per_ep = []
    # ê¸¸ì´ ì •ê·œí™”(ìµœì†Ÿê°’ ê¸°ì¤€) â†’ ì‹œê°í™” ì½”ë“œê°€ stack ê°€ëŠ¥í•œ ëª¨ì–‘ì„ ê¸°ëŒ€í•¨
    if not per_ep:
        return np.empty((0, 0))
    min_len = min(len(v) for v in per_ep)
    if min_len == 0:
        return np.empty((0, 0))
    return np.stack([v[:min_len] for v in per_ep], axis=0)

def _stack_ragged(obj_arr, target_len=None):
    """
    ì—í”¼ì†Œë“œë³„ ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤(2D/3D)ë¥¼ (episodes, T, ...)ë¡œ ìŠ¤íƒí•©ë‹ˆë‹¤.
    target_lenì´ ì£¼ì–´ì§€ë©´ ì•ì—ì„œë¶€í„° ê·¸ ê¸¸ì´ì— ë§ì¶° ì˜ë¼ ìŠ¤íƒí•©ë‹ˆë‹¤.
    """
    arrs = [np.asarray(ep) for ep in obj_arr]
    lens = [a.shape[0] for a in arrs] if arrs else [0]
    if not arrs or min(lens) == 0:
        return np.empty((0, 0))
    T = min(lens) if target_len is None else min(target_len, min(lens))
    return np.stack([a[:T] for a in arrs], axis=0)

# ------------------------------------------------------------

# (ì„ íƒ) í‰ê°€ ì €ì¥ ë¶„ê¸°ì—ì„œ NameError ë°©ì§€ìš© ê¸°ë³¸ê°’
X_ev = None
U_ev = None
R_ev = None
d_ev = None

# --------------------------------------------------------

STORE_DATA = True
PLOT = True

# 0) Config ë¡œë”©
if len(sys.argv) > 1:
    config_file = sys.argv[1]
    mod = importlib.import_module(f"sims.configs.{config_file}")
    test = mod.Test()
else:
    from sims.configs.test_80 import Test  # type: ignore
    test = Test()

# 1) ê³µí†µ ê²½ë¡œ/ë””ë ‰í„°ë¦¬
os.makedirs("results", exist_ok=True)
CKPT_PATH = f"results/{test.test_ID}_ckpt.pkl"   # ì˜ˆ: results/test_80_ckpt.pkl

# ---------- ì²´í¬í¬ì¸íŠ¸ ìœ í‹¸ ----------
def agent_param_values(agent):
    """ì—ì´ì „íŠ¸ì˜ learnable íŒŒë¼ë¯¸í„° í˜„ì¬ ê°’ ì‚¬ì „ìœ¼ë¡œ ì¶”ì¶œ"""
    out = {}
    for name, lp in agent.learnable_parameters.items():
        out[name] = np.array(lp.value, dtype=float)
    return out

def load_agent_param_values(agent, values: dict):
    """ì €ì¥ëœ íŒŒë¼ë¯¸í„° ê°’ì„ ì—ì´ì „íŠ¸ì— ì£¼ì…"""
    for name, val in values.items():
        if name in agent.learnable_parameters:
            agent.learnable_parameters[name].value = np.array(val, dtype=float)

def save_ckpt(ep_idx: int, agent, meta=None):
    data = {
        "episode_index": ep_idx,
        "test_id": test.test_ID,
        "params": agent_param_values(agent),
        "meta": meta or {"time": time.time()},
    }
    with open(CKPT_PATH, "wb") as f:
        pickle.dump(data, f)

def load_ckpt_if_exists(agent):
    if not os.path.exists(CKPT_PATH):
        return None
    with open(CKPT_PATH, "rb") as f:
        data = pickle.load(f)
    if data.get("test_id") != test.test_ID:
        return None  # ë‹¤ë¥¸ ì‹¤í—˜ì˜ ckptëŠ” ë¬´ì‹œ
    load_agent_param_values(agent, data.get("params", {}))
    return data
# -------------------------------------

np_random = np.random.default_rng(test.seed if getattr(test, "model_parameters_from_seed", False) else 1)

episode_len = test.ep_len
train_env = MonitorEpisodes(
    TimeLimit(
        LettuceGreenHouse(
            growing_days=test.num_days,
            model_type=test.base_model,
            cost_parameters_dict=test.rl_cost,
            disturbance_profiles_type=test.disturbance_type,
            noisy_disturbance=test.noisy_disturbance,
            clip_action_variation=test.clip_action_variation,
        ),
        max_episode_steps=int(episode_len),
    )
)
if test.normalize_reward:
    train_env = NormalizeReward(train_env, test.discount_factor)

eval_env = MonitorEpisodes(
    TimeLimit(
        LettuceGreenHouse(
            growing_days=test.num_days,
            model_type=test.base_model,
            cost_parameters_dict=test.rl_cost,
            disturbance_profiles_type=test.disturbance_type,
            noisy_disturbance=test.noisy_disturbance,
            clip_action_variation=test.clip_action_variation,
        ),
        max_episode_steps=int(episode_len),
    )
)

prediction_model: Literal["euler", "rk4"] = "rk4"
mpc = LearningMpc(
    greenhouse_env=train_env,
    test=test,
    prediction_model=prediction_model,
    np_random=np_random,
    constrain_control_rate=True,
)

param_bounds = Model.get_learnable_parameter_bounds()
param_bounds.update(test.learn_bounds)

learnable_pars = LearnableParametersDict[cs.SX](
    (
        LearnableParameter(
            name,
            val.shape,
            val,
            sym=mpc.parameters[name],
            lb=param_bounds[name][0] if name in param_bounds.keys() else -np.inf,
            ub=param_bounds[name][1] if name in param_bounds.keys() else np.inf,
        )
        for name, val in mpc.learnable_pars_init.items()
    )
)

agent = Evaluate(
    Log(
        RecordUpdates(
            GreenhouseLearningAgent(
                mpc=mpc,
                update_strategy=test.update_strategy,
                discount_factor=mpc.discount_factor,
                optimizer=test.optimizer,
                learnable_parameters=learnable_pars,
                fixed_parameters=mpc.fixed_pars,
                exploration=test.exploration,
                experience=test.experience,
                hessian_type=test.hessian_type,
                record_td_errors=True,
            )
        ),
        level=logging.DEBUG,
        log_frequencies={"on_timestep_end": 1},
        to_file=True,
        log_name=f"log_{test.test_ID}",
    ),
    eval_env,
    hook="on_episode_end",
    # â˜… ì§§ì€ ëŸ¬ë‹ì—ì„œë„ ìµœì†Œ 1íšŒ í‰ê°€ê°€ ëŒë„ë¡
    frequency=1,
    eval_immediately=True,
    deterministic=True,
    raises=False,
    env_reset_options={
        "initial_day": test.initial_day,
        "noise_coeff": test.noise_coeff if test.noisy_disturbance else 1.0,
    } if test.disturbance_type == "single" else {},
    seed=test.seed,
)

# ---------- ì•ˆì „ ì¢…ë£Œìš© ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ----------
current_ep_for_sig = -1
def _save_and_exit(signum, frame):
    try:
        if 'agent' in globals():
            save_ckpt(current_ep_for_sig, agent, meta={"signal": int(signum), "time": time.time()})
    finally:
        os._exit(1)

for sig in (signal.SIGINT, signal.SIGTERM):
    try:
        signal.signal(sig, _save_and_exit)
    except Exception:
        pass
# -----------------------------------------------

# ---------- Resume ----------
resume_info = load_ckpt_if_exists(agent)
start_ep = 0
if resume_info is not None:
    start_ep = int(resume_info.get("episode_index", -1)) + 1
    print(f"[CKPT] Resuming from episode {start_ep} with params restored.")
# ---------------------------

# ---------- í•™ìŠµ ë£¨í”„(ì—í”¼ì†Œë“œ 1ê°œì”©) ----------
for ep in range(start_ep, test.num_episodes):
    current_ep_for_sig = ep
    agent.train(
        env=train_env,
        episodes=1,  # í•œ ë²ˆì— 1ê°œ
        seed=test.seed,
        raises=False,
        env_reset_options={
            "initial_day": test.initial_day,
            "noise_coeff": test.noise_coeff if test.noisy_disturbance else 1.0,
        } if test.disturbance_type == "single" else {},
    )
    save_ckpt(ep, agent, meta={"after_episode": ep, "time": time.time()})
    print(f"[CKPT] Saved at episode {ep}")

# ëª¨ë“  ì—í”¼ì†Œë“œ ì™„ë£Œ â†’ ckpt ì •ë¦¬(ì„ íƒ) 2025/09/29 ì£¼ì„ì²˜ë¦¬
# try:
#     if os.path.exists(CKPT_PATH):
#         os.remove(CKPT_PATH)
#         print("[CKPT] Completed. Checkpoint removed.")
# except Exception:
#     pass
# -----------------------------------------------

print(np.mean(agent.solve_times))

# ---------- ë°ì´í„° ì¶”ì¶œ ----------

# Train ë°ì´í„° (ë¨¼ì € êº¼ë‚´ì„œ ì—í”¼ì†Œë“œë³„ ì›ì‹œ ì‹œí€€ìŠ¤ í™•ë³´: ragged/object)
X_tr = np.asarray(train_env.observations, dtype=object)   # ê° ep: (T_x_plus1, nx)
U_tr = squeeze_last_if_one(train_env.actions)             # ê° ep: (T_u, nu)
R_tr = np.asarray(train_env.rewards, dtype=object)        # ê° ep: (T_r,)
d_tr = stack_disturbances(train_env)                      # ê° ep: (T_d, nd)

# TDë¥¼ ì—í”¼ì†Œë“œ ê²½ê³„ ê¸°ì¤€ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì¬êµ¬ì„±
TD = build_TD_matrix(agent.td_errors, R_tr, test.num_episodes)

# íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬ reshapeë„ ì•ˆì „í•˜ê²Œ (ì—í”¼ì†Œë“œ ê²½ê³„ ê¸°ì¤€)
param_dict = {}
for key, val in agent.updates_history.items():
    temp = [val[0]] * test.skip_first
    val = [*temp, *val[1:]]
    flat = np.asarray(val, dtype=float).ravel()
    ep_lens = [len(r) for r in R_tr]
    total = sum(ep_lens)
    flat = flat[:total]
    if len(ep_lens) > 1:
        splits = np.cumsum(ep_lens[:-1])
        per_ep = np.split(flat, splits)
    else:
        per_ep = [flat]
    min_len = min(len(v) for v in per_ep) if per_ep else 0
    if min_len == 0:
        param_dict[key] = np.empty((0, 0))
    else:
        param_dict[key] = np.stack([v[:min_len] for v in per_ep], axis=0)

# ---------- ê¸¸ì´ ì •ë ¬ & 3D ìŠ¤íƒ ----------
# ê° ì‹œí€€ìŠ¤ì˜ ìµœì†Œ ê¸¸ì´ ê³„ì‚°
Tx = min(len(np.asarray(ep)) for ep in X_tr) if len(X_tr) else 0      # ìƒíƒœ ê¸¸ì´ (T_x_plus1)
Tu = min(len(np.asarray(ep)) for ep in U_tr) if len(U_tr) else 0      # ì…ë ¥ ê¸¸ì´ (T_u)
Tr = min(len(np.asarray(ep)) for ep in R_tr) if len(R_tr) else 0      # ë³´ìƒ ê¸¸ì´ (T_r)
Td = min(len(np.asarray(ep)) for ep in d_tr) if len(d_tr) else 0      # ì™¸ë€ ê¸¸ì´ (T_d)

# ê³µí†µ ì‹œê°„ì¶• T ì„¤ì •: XëŠ” (T+1), U/R/dëŠ” (T)
T = max(0, min(Tu, Tr, Td, Tx - 1))

# Tê°€ 0ì´ë©´(ë°ì´í„°ê°€ ë¹„ì–´ ìˆìœ¼ë©´) í”Œë¡¯ì€ ê±´ë„ˆë›°ê³  ì €ì¥ë§Œ
if T <= 0:
    print("[WARN] No timesteps to plot (T<=0). Skipping plots.")
    PLOT = False


# ì •ë ¬ëœ 3D/2D í…ì„œë¡œ ë³€í™˜
X = _stack_ragged(X_tr, target_len=T + 1)   # (episodes, T+1, nx?) or (episodes, T+1)
U = _stack_ragged(U_tr, target_len=T)       # (episodes, T,   nu?) or (episodes, T)
R = _stack_ragged(R_tr, target_len=T)       # (episodes, T)
d = _stack_ragged(d_tr, target_len=T)       # (episodes, T,   nd?) or (episodes, T)

# ğŸ”§ ì°¨ì› ë³´ì •: 2Dë¡œ ë–¨ì–´ì¡Œìœ¼ë©´ ë§ˆì§€ë§‰ ì¶•ì„ ì¶”ê°€í•´ 3Dë¡œ ë§ì¶¤
if X.ndim == 2: X = X[:, :, np.newaxis]
if U.ndim == 2: U = U[:, :, np.newaxis]
if d.ndim == 2: d = d[:, :, np.newaxis]


# (ì„ íƒ) ë°©ì–´ì  ì²´í¬
# assert X.ndim == 3 and U.ndim == 3 and d.ndim == 3, f"Shapes not 3D: {X.shape}, {U.shape}, {d.shape}"
# assert X.shape[1] == U.shape[1] + 1 == d.shape[1] + 1 == R.shape[1] + 1, "Time lengths misaligned"

# ---------- í”Œë¡¯ ----------
if PLOT:
    # â€» ragged ì›ë³¸(X_tr ë“±)ì´ ì•„ë‹ˆë¼, ì •ë ¬ëœ í…ì„œ(X/U/R/d)ë¥¼ ë„˜ê¹ë‹ˆë‹¤.
    plot_greenhouse(X, U, d, R, TD)
# -------------------------

# ---------- ì €ì¥ ----------
identifier_tr = f"results/{test.test_ID}_train"
identifier_ev = f"results/{test.test_ID}_eval"

if STORE_DATA:
    with open(f"{identifier_tr}.pkl", "wb") as file:
        pickle.dump(
            {
                "name": identifier_tr,
                "X": X,           # ì •ë ¬ëœ í…ì„œ ì €ì¥
                "U": U,
                "R": R,
                "d": d,
                "TD": TD,
                "param_dict": param_dict,
            },
            file,
        )
    if X_ev is not None:
        with open(f"{identifier_ev}.pkl", "wb") as file:
            pickle.dump(
                {"name": identifier_ev, "X": X_ev, "U": U_ev, "R": R_ev, "d": d_ev},
                file,
            )
# -------------------------
