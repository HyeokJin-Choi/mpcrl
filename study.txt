// https://github.com/SamuelMallick/mpcrl-greenhouse 를 기반으로 연구를 진행.
상추(Lettuce) 재배 온실 환경을 시뮬레이션하면서, 그 안에 **MPC(Model Predictive Control)**와 **강화학습(RL)**을 결합해 제어 성능을 개선하는 연구 코드

*** 환경 모델 ***
LettuceGreenHouse라는 환경 클래스를 정의해서, 온실 내 상태(온도, 습도, CO₂, 빛 등)와 외부 교란(날씨, 일사량 등)을 모사.
*** 재배 작물 *** 
상추 (lettuce).
온실에서 상추가 자라는 과정을 수학적/물리적 모델로 시뮬레이션.
하루 단위(num_days)로 성장 과정을 반영.
*** 제어 목표 ***
상추가 잘 자랄 수 있는 최적 환경(예: 온도·습도·CO₂ 농도 유지) 유지.
동시에 에너지 소비(히터, 팬, CO₂ 주입 등) 최소화.
*** 도입된 기법 ***
MPC: 물리적 모델 기반 예측 제어 → 안정성 보장.
강화학습: MPC의 모델 파라미터를 학습·보정하여 더 나은 제어 성능 달성.

-----<Code Analysis>-----
*** q_learning_greenhouse.py ***
# 시뮬레이션 환경(LettuceGreenHouse)을 초기화할 때 주어지는 파라미터들. 즉, 실제 상추 재배 과정을 모사하는 “가상 온실 환경”의 조건을 어떻게 설정할지를 지정하는 부분.
LettuceGreenHouse(
    growing_days=test.num_days,              # 상추를 키우는 총 기간 (재배일수, 시뮬레이션 horizon)
    model_type=test.base_model,              # 어떤 물리/수학 모델을 쓸지 (예: euler vs rk4, 단순 모델 vs 정밀 모델)
    cost_parameters_dict=test.rl_cost,       # 제어 비용/보상 함수 파라미터 (에너지 소비, 작물 성장 효율 등 가중치)
    disturbance_profiles_type=test.disturbance_type,  # 외부 교란(날씨 패턴) 시나리오 선택
    noisy_disturbance=test.noisy_disturbance,# 교란에 노이즈를 추가할지 여부 (현실성 ↑)
    clip_action_variation=test.clip_action_variation  # 제어 입력 변화량을 제한할지 여부 (안정성 ↑)
)

ex) 
- growing_days=90이면 90일간의 온실 운영을 시뮬레이션.
- disturbance_profiles_type="weather_based"라면 실제 기상 데이터를 반영.
- rl_cost에 따라 보상 함수가 달라져서 RL이 학습하는 목표(작물 품질 vs 에너지 절감)가 바뀜.
- clip_action_variation=True이면 제어 신호가 갑자기 튀지 않게 제한.

